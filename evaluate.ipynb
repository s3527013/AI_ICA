{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Delivery Route Optimization Analysis with Google Gemini\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook runs the reinforcement learning simulation for delivery route optimization and uses Google's Gemini AI to interpret the results.\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Prerequisites\\n\",\n",
    "    \"Ensure you have the following installed:\\n\",\n",
    "    \"`pip install google-generativeai osmnx networkx folium torch matplotlib numpy`\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import os\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"from IPython.display import Markdown, display\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Import project modules\\n\",\n",
    "    \"from main import generate_random_locations, train_tabular_agent, train_dqn_agent, evaluate_agent\\n\",\n",
    "    \"from environment import DeliveryEnvironment\\n\",\n",
    "    \"from q_learning import QLearningAgent\\n\",\n",
    "    \"from sarsa import SarsaAgent\\n\",\n",
    "    \"from dqn import DQNAgent\\n\",\n",
    "    \"from main_with_google_ai import GoogleAIModelExplainer\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- SETUP API KEY ---\\n\",\n",
    "    \"# If you haven't set GOOGLE_API_KEY in your environment variables, uncomment and set it here:\\n\",\n",
    "    \"# os.environ[\\\"GOOGLE_API_KEY\\\"] = \\\"YOUR_ACTUAL_API_KEY_HERE\\\"\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# --- CONFIGURATION ---\\n\",\n",
    "    \"CITY = \\\"Middlesbrough\\\"\\n\",\n",
    "    \"NUM_PARCELS = 10  # Reduced for faster execution in notebook\\n\",\n",
    "    \"DISTANCE_METRIC = 'network' # 'network', 'manhattan', or 'driving'\\n\",\n",
    "    \"NUM_EPISODES = 1000\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# --- INITIALIZE ENVIRONMENT ---\\n\",\n",
    "    \"print(f\\\"Generating locations in {CITY}...\\\")\\n\",\n",
    "    \"locations = generate_random_locations(CITY, NUM_PARCELS + 1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"if locations is not None:\\n\",\n",
    "    \"    print(f\\\"Initializing Environment with {DISTANCE_METRIC} metric...\\\")\\n\",\n",
    "    \"    env = DeliveryEnvironment(locations=locations, city_name=CITY, distance_metric=DISTANCE_METRIC)\\n\",\n",
    "    \"    print(f\\\"Environment ready. {env.num_locations} locations.\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"Failed to generate locations.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# --- INITIALIZE AGENTS ---\\n\",\n",
    "    \"agents = {\\n\",\n",
    "    \"    \\\"Q-Learning\\\": QLearningAgent(action_space=list(range(env.num_locations))),\\n\",\n",
    "    \"    \\\"SARSA\\\": SarsaAgent(action_space=list(range(env.num_locations))),\\n\",\n",
    "    \"    \\\"DQN\\\": DQNAgent(state_size=env.get_state_size(), action_size=env.num_locations)\\n\",\n",
    "    \"}\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# --- TRAINING LOOP ---\\n\",\n",
    "    \"reward_histories = {}\\n\",\n",
    "    \"final_results = {}\\n\",\n",
    "    \"best_route_info = {\\\"agent\\\": None, \\\"route\\\": [], \\\"distance\\\": float('inf')}\\n\",\n",
    "    \"\\n\",\n",
    "    \"for name, agent in agents.items():\\n\",\n",
    "    \"    print(f\\\"Training {name} for {NUM_EPISODES} episodes...\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if isinstance(agent, DQNAgent):\\n\",\n",
    "    \"        reward_histories[name] = train_dqn_agent(agent, env, NUM_EPISODES)\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        reward_histories[name] = train_tabular_agent(agent, env, NUM_EPISODES)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Evaluate\\n\",\n",
    "    \"    route, distance = evaluate_agent(agent, env)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Calculate metrics for AI analysis\\n\",\n",
    "    \"    avg_reward = np.mean(reward_histories[name][-100:])\\n\",\n",
    "    \"    final_results[name] = {\\n\",\n",
    "    \"        \\\"total_distance_km\\\": distance,\\n\",\n",
    "    \"        \\\"avg_final_reward\\\": avg_reward,\\n\",\n",
    "    \"        \\\"convergence_speed\\\": \\\"Fast\\\" if avg_reward > -1000 else \\\"Slow\\\" # Simple heuristic\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"  > Final Distance: {distance:.2f} km\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if distance < best_route_info[\\\"distance\\\"]:\\n\",\n",
    "    \"        best_route_info = {\\\"agent\\\": name, \\\"route\\\": route, \\\"distance\\\": distance}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nTraining Complete.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# --- VISUALIZATION ---\\n\",\n",
    "    \"plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"for name, rewards in reward_histories.items():\\n\",\n",
    "    \"    # Smooth curves\\n\",\n",
    "    \"    window = 50\\n\",\n",
    "    \"    if len(rewards) >= window:\\n\",\n",
    "    \"        avg_rewards = np.convolve(rewards, np.ones(window)/window, mode='valid')\\n\",\n",
    "    \"        plt.plot(avg_rewards, label=name)\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        plt.plot(rewards, label=name)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.title(\\\"Agent Learning Curves\\\")\\n\",\n",
    "    \"plt.xlabel(\\\"Episode\\\")\\n\",\n",
    "    \"plt.ylabel(\\\"Reward (Moving Avg)\\\")\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"plt.grid(True)\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# --- GOOGLE GEMINI ANALYSIS ---\\n\",\n",
    "    \"print(\\\"Initializing Google AI Explainer...\\\")\\n\",\n",
    "    \"explainer = GoogleAIModelExplainer()\\n\",\n",
    "    \"\\n\",\n",
    "    \"env_config = {\\n\",\n",
    "    \"    \\\"city\\\": CITY,\\n\",\n",
    "    \"    \\\"num_parcels\\\": NUM_PARCELS,\\n\",\n",
    "    \"    \\\"distance_metric\\\": DISTANCE_METRIC,\\n\",\n",
    "    \"    \\\"episodes\\\": NUM_EPISODES\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"if explainer.available:\\n\",\n",
    "    \"    print(\\\"\\\\n--- AI Performance Analysis ---\\\")\\n\",\n",
    "    \"    analysis = explainer.analyze_performance(final_results, env_config)\\n\",\n",
    "    \"    display(Markdown(analysis))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"\\\\n--- Full Training Report ---\\\")\\n\",\n",
    "    \"    report = explainer.generate_training_report(reward_histories, final_results, env_config)\\n\",\n",
    "    \"    display(Markdown(report))\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"Google AI not available. Please check your API key.\\\")\\n\",\n",
    "    \"    print(\\\"Results Summary:\\\", final_results)\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.13\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}"
   ],
   "id": "5ff9087e763a31b5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
